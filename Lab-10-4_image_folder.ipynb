{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab-10-4_image_folder.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM6VoitT8/1zEG+cCD7li2F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lab 10-4: ImageFolder - 자신의 데이터셋 학습시키기\n"],"metadata":{"id":"noxx0al0SIF0"}},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"VtZKXTl9STnJ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from matplotlib.pyplot import imshow\n","%matplotlib inline"],"metadata":{"id":"hA8gx7roSYY-","executionInfo":{"status":"ok","timestamp":1657897337059,"user_tz":-540,"elapsed":480,"user":{"displayName":"‍노장한[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"02460474193047331263"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## ImageFolder Example"],"metadata":{"id":"o8llgaaaS1TK"}},{"cell_type":"code","source":["trans = transforms.Compose([\n","                            transforms.Resize((64,128))\n","])\n","\n","train_data = torchvision.datasets.ImageFolder(root='custom_data/origin_data',\n","                                              transform= trans)\n","\n","for i, value in enumerate(train_data):\n","  data, label = value\n","  print(i, data, label)\n","\n","  if(label==0):\n","    data.save('custom_data/train_data/gray/{}_{}'.format(i, label))\n","  else:\n","    data.save('custom_data/train_data/red/{}_{}'.format(i, label))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"-inHd1snS4f_","executionInfo":{"status":"error","timestamp":1657897392167,"user_tz":-540,"elapsed":511,"user":{"displayName":"‍노장한[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"02460474193047331263"}},"outputId":"3c6f88d5-c21d-4216-b2cc-41d86c87eb07"},"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-9168ed90e3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_data = torchvision.datasets.ImageFolder(root='custom_data/origin_data',\n\u001b[0;32m----> 6\u001b[0;31m                                               transform= trans)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         )\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"]}]},{"cell_type":"markdown","source":["## Use ImageFolder"],"metadata":{"id":"8t3gpVbgUR1U"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","#For reproducibility\n","torch.manual_seed(777)\n","if device == 'cuda':\n","  torch.cuda.manual_seed_all(777)\n","\n","# data & data_loader\n","trans = transforms.Compose([\n","                            transforms.ToTensor()\n","])\n","\n","train_data = torchvision.datasets.ImageFolder(root='./custom_data/train_data',\n","                                              transforms = trans)\n","\n","data_loader = torch.utils.data.DataLoader(dataset= train_data,\n","                                          batch_size = 8,\n","                                          shuffle = True,\n","                                          num_workers=2)\n","\n","# Model\n","class CNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.layer1 = nn.Sequential(\n","        nn.Conv2d(3,6,5),\n","        nn.ReLU(),\n","        nn.MaxPool2d()\n","    )\n","    self.layer2 = nn.Sequential(\n","        nn.Conv2d(6,16,5),\n","        nn.ReLU(),\n","        nn.MaxPool2d()\n","    )\n","    self.layer1 = nn.Sequential(\n","        nn.Linear(16*13*29, 120),\n","        nn.ReLU(),\n","        nn.Linear(120, 2)\n","    )\n","  \n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = out.view(out.shape[0], -1)\n","    out = self.layer3(out)\n","    return out\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"MQshuKFFUYTo","executionInfo":{"status":"error","timestamp":1657897714212,"user_tz":-540,"elapsed":500,"user":{"displayName":"‍노장한[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"02460474193047331263"}},"outputId":"10bae37e-cce4-40a2-dc8c-c4def2b022f4"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-726e98e91b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"]}]},{"cell_type":"code","source":["# testing\n","net = CNN().to(device)\n","test_input = torch.Tensor(3,3,64,128).to(device)\n","test_out = net(test_input)"],"metadata":{"id":"ZucPJqSGaDgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#cost & optimizer\n","optimizer = torch.optim.Adam(net.parameters(), lr= 0.00005)\n","loss_func = nn.CrossEntropyLoss().to(device)\n","\n","# training\n","total_batch = len(data_loader)\n","\n","epochs = 7\n","for epoch in range(epochs):\n","  avg_cost = 0\n","  for num, data in enumerate(data_loader):\n","    X, Y = data\n","    \n","    X = X.to(device)\n","    Y = Y.to(device)\n","\n","    optimizer.no_grad()\n","    out = net(X)\n","    loss = loss_func(out, Y)\n","    loss.backward()\n","    optimizer.step()\n","\n","    avg_cost += loss / total_batch\n","  \n","  priprint('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n","print('Learning Finished!')"],"metadata":{"id":"P83FijmzaSnu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save model state\n","torch.save(net.state_dict(), './model/model.pth')\n","\n","#load model state\n","new_net = CNN().to(device)\n","new_net.load_state_dict(torch.load('./model/model.pth'))\n","\n","# compare\n","print(net.layer1[0])\n","print(new_net.layer1[0])\n","\n","print(net.layer1[0].weight[0][0][0])\n","print(new_net.layer1[0].weight[0][0][0])\n","\n","net.layer1[0].weight[0] == new_net.layer1[0].weight[0]"],"metadata":{"id":"sKU4CUWIbf5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test\n","trans = torchvision.transforms.Compose([\n","                                        transforms.Resize((64, 128))\n","                                        transforms.ToTensor()\n","])\n","test_data = torchvision.datasets.ImageFolder(root='./custom_data/test_data',\n","                                             transform= trans)\n","\n","test_set = torch.utils.data.DataLoader(dataset= test_data,\n","                                       batch_size= len(test_data))\n","\n","with torch.no_grad():\n","  for num,data in enumerate(test_set):\n","    X, Y = data\n","    X = X.to(device)\n","    Y = Y.to(device)\n","\n","    prediction = net(X)\n","    correct_prediction = torch.argmax(prediction, 1) == Y\n","    accuracy = correct_prediction.float().mean()\n","\n","    print('Accuracy:', accuracy.item())"],"metadata":{"id":"aUOT339IaSsQ"},"execution_count":null,"outputs":[]}]}